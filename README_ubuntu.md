# CreaCube

Les instructions qui suivent ont √©t√© test√©es sur un ordinateur fonctionnant sous Ubuntu 18, dot√© d'un processeur CPU Intel¬Æ Core‚Ñ¢ i5-10310U 1.70GHz √ó 8, de 32 Go de m√©moire vive et d‚Äôune carte graphique int√©gr√©e Intel¬Æ UHD (CML GT2).

## Installation

### 1. Installation de pipenv et Python 3.9

Le tutoriel suivant utilise [Pipenv](https://pypi.org/project/pipenv/) pour g√©rer les environnements virtuels. Si vous pr√©f√©rez utiliser Anaconda, veuillez vous reporter aux instructions pour Windows.

Les librairies ont √©t√© test√©es sous Python 3.9, il est donc recommand√© d'utiliser la m√™me version et de l'installer si vous ne l'avez pas d√©j√† (diff√©rentes versions de python peuvent √™tre install√©es en parall√®le sans interf√©rence gr√¢ce aux environnements virtuels) :
```
sudo apt install python 3.9
```

Pipenv peut √™tre install√© de cette mani√®re (ou voir [ici](https://pipenv.pypa.io/en/latest/#install-pipenv-today) pour plus d'informations)
```
sudo apt install pipenv
```

### 2. Installer Cuda

N'ayant pas de carte graphique de marque Nvidia j'ai pass√© cette √©tape. Si besoin, des instructions sont disponibles [ici](https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html).

### 3. T√©l√©charger le projet depuis le git

Clonez ce git √† l'aide de la commande suivante :
```
git clone https://github.com/TheoCarme/CreaCube.git
```

### 4. Installation des d√©pendances

- Si le Pipfile n'est pas d√©j√† cr√©√©:

```
cd path\to\the\project
pipenv install pycocotools alive_progress
pipenv install torch torchvision torchaudio
```
Cette derni√®re ligne est √† adapter si vous souhaitez utiliser une carte graphique Nvidia.

Puis, pour installer Yolox:
```
cd YOLOX
pipenv install -r requirements.txt
pipenv shell # activer l'environnement virtuel
pip install -v -e .
```

- Si le Pipfile est d√©j√† cr√©√©:
```
cd path\to\the\project
pipenv install 
cd YOLOX
pipenv shell # activer l'environnement virtuel
pip install -v -e .
```

## Utilisation

### 1. Aide sur la commande

```
cd path\to\the\project
pipenv shell # activer l'environnement virtuel
python combined_detection.py --help
```
La derni√®re ligne affiche les diff√©rends arguments que peut accepter le programme. Ces arguments sont les suivants :  
| Argument | Description |
| :------: | :---------- |
| -m / --model |¬†Permet de pr√©ciser le chemin du mod√®le ONNX √† utiliser. |
| -v / --video_path |¬†Permet de donner le chemin de la vid√©o √† analyser. |
| -o / --output_dir |¬†Permet de donner le chemin du dossier l√† o√π sera cr√©e si demand√© le dossier contenant la vid√©o annot√©e et le fichier csv. |
| -s / --score_thr |¬†Permet de fixer un seuil au score de confiance des cubes, en dessous duquel les cubes ne seront pas dessin√©s sur la vid√©o. Ce seuil est par d√©faut fix√© √† 0.3. |
| -S / --start |¬†Permet d'indiquer un nombre de seconde √† ignorer au d√©but de la vid√©o. |
| -E / --end |¬†Permet d'indiquer un nombre de seconde √† ignorer √† la fin de la vid√©o. |
| -n / --num_hands |¬†Permet d'indiquer le nombre maximum de main √† d√©tecter sur la vid√©o. Ce maximum est par d√©faut fix√© √† 4. |
| -c / --csv |¬†Permet de demander au programme de √©crire le fichier csv contenant les traces des objets suivis. |
| -w / --write_video |¬†Permet de demander au programme d'√©crire la vid√©o avec les objets suivis dessin√©s dessus. |
| -d / --display |¬†Permet de demander au programme d'afficher chaque trame trait√©e avec les objets suivis dessin√©s dessus. |

La ligne pour √©xecuter le programme pourra donc ressembler √† cela :
```
python .\combined_detection.py -m ..\Project_Data\ONNX_Models\yolox_s.onnx -v C:\Users\theon\Documents\Stage_XLIM\20220330T072838Z\scenevideo.mp4 -o ..\Results -n 2 -c -w -d
```

Entrer √† chaque fois les chemin vers le mod√®le, la vid√©o et dossier des r√©sultats peut vite devenir r√©barbatif. Pour rem√©dier √† cela vous pouvez aller modifier les valeurs par d√©faut dans la premi√®re fonction nomm√©e "make_parser" dans le fichier "combined_detection.py"


### 2. Exemple

J'ai ajout√© 3 sous-dossiers (ignor√©s par git) videos, onyx_models et yolox_outputs, contenant :
- videos
  - une vid√©o de test p359.mp4 (t√©l√©charg√© [ici](https://creamaker.univ-cotedazur.fr/))
- onyx_models
  - yolox_s.onnx (t√©l√©charg√© [ici](https://drive.google.com/drive/folders/1Wp4CAXRcb4OCIt-8F-fsc5UlX-_H_CzD))
- yolox_outputs
  - dossier vide avant de faire tourner la commande

Nous pouvons alors g√©n√©rer la sortie du mod√®le pour une des vid√©os :
```
python combined_detection.py -m onyx_models/yolox_s.onnx -v videos/p359.mp4 -o yolox_outputs -n 2 -c -w -d


üî¥ Traceback (most recent call last):
  File "/home/chloe/Projects/xlim-creacube/combined_detection.py", line 262, in <module>
    cubes_detector = Cubes_Detector(args.model, input_shape)
  File "/home/chloe/Projects/xlim-creacube/cubes_detector.py", line 21, in __init__
    self.session = onnxruntime.InferenceSession(model)
  File "/home/chloe/.local/share/virtualenvs/xlim-creacube-iwzZKUKy/lib/python3.9/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 347, in __init__
    self._create_inference_session(providers, provider_options, disabled_optimizers)
  File "/home/chloe/.local/share/virtualenvs/xlim-creacube-iwzZKUKy/lib/python3.9/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 375, in _create_inference_session
    raise ValueError(
ValueError: This ORT build has ['TensorrtExecutionProvider', 'CUDAExecutionProvider', 'CPUExecutionProvider'] enabled. Since ORT 1.9, you are required to explicitly set the providers parameter when instantiating InferenceSession. For example, onnxruntime.InferenceSession(..., providers=['TensorrtExecutionProvider', 'CUDAExecutionProvider', 'CPUExecutionProvider'], ...)
```

R√©solu en ajoutant les providers √† la ligne 21 de cubes_detector.py

`self.session = onnxruntime.InferenceSession(model, providers=['CUDAExecutionProvider', 'CPUExecutionProvider'])`